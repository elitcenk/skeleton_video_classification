{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "advanced.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5rc1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3wF5wszaj97Y"
      },
      "source": [
        "# TensorFlow 2 quickstart for experts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hiH7AC-NTniF"
      },
      "source": [
        "This is a [Google Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb) notebook file. Python programs are run directly in the browserâ€”a great way to learn and use TensorFlow. To follow this tutorial, run the notebook in Google Colab by clicking the button at the top of this page.\n",
        "\n",
        "1. In Colab, connect to a Python runtime: At the top-right of the menu bar, select *CONNECT*.\n",
        "2. Run all the notebook code cells: Select *Runtime* > *Run all*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eOsVdx6GGHmU"
      },
      "source": [
        "Download and install the TensorFlow 2 package:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ioLbtB3uGKPX",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QS7DDTiZGRTo"
      },
      "source": [
        "Import TensorFlow into your program:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0trJmd6DjqBZ",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import os\n",
        "import random\n",
        "\n",
        "import h5py\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Activation, LSTM, Bidirectional, Input, Reshape, Permute, Lambda, TimeDistributed, SpatialDropout1D, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.python.keras.layers.merge import Add, Multiply, multiply\n",
        "from tensorflow.python.keras.models import Model\n",
        "from tensorflow.python.keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7NAbSZiaoJ4z"
      },
      "source": [
        "Load and prepare the [MNIST dataset](http://yann.lecun.com/exdb/mnist/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JqFRS6K07jJs",
        "colab": {}
      },
      "source": [
        "def load_seq_lst(lst_name, num_seq, ovr_num=None, num_joints=25, num_class=52):\n",
        "    # the reverse process of load_sequence() method in pku_dataset class\n",
        "    # the output is a list of skeleton sequence of variable length\n",
        "    # for training set, samples clips around intervals of actions\n",
        "    assert (os.path.isfile(lst_name + '.txt') and os.path.isfile(lst_name + '.h5'))\n",
        "    if ovr_num is None:\n",
        "        ovr_num = int(num_seq / 2)\n",
        "    keyname_lst = [item.strip().split() for item in open(lst_name + '.txt', 'r').readlines()]\n",
        "    X = []\n",
        "    Y = []\n",
        "    vid_list = []\n",
        "    start_list = []\n",
        "    with h5py.File(lst_name + '.h5', 'r') as hf:\n",
        "        for item in keyname_lst:\n",
        "            skeleton = np.asarray(hf.get(item[0]))\n",
        "            # skeleton = skeleton.reshape((skeleton.shape[0], self._num_joints, self._dim_point ))\n",
        "            skeleton1 = skeleton[:, 0:75].reshape((skeleton.shape[0], num_joints, 3))\n",
        "            skeleton2 = skeleton[:, 75:].reshape((skeleton.shape[0], num_joints, 3))\n",
        "            skeleton = np.concatenate((skeleton1, skeleton2), axis=-1)\n",
        "\n",
        "            labels = np.asarray(hf.get(item[1]), dtype=int)\n",
        "            labels_pertime = np.zeros((skeleton.shape[0]), dtype=np.int32)\n",
        "            for clip_idx in range(len(labels)):\n",
        "                # notice: for detection, labels start from 1, as there are empty clips for the input stream\n",
        "                labels_pertime[labels[clip_idx][1]:labels[clip_idx][2]] = labels[clip_idx][0] + 1\n",
        "            labels_pertime = labels_pertime.astype(np.int32)\n",
        "            labels_pertime = np_utils.to_categorical(labels_pertime, num_class)\n",
        "\n",
        "            if skeleton.shape[0] > num_seq:\n",
        "                start = 0\n",
        "                while start + num_seq < skeleton.shape[0]:\n",
        "                    X.append(skeleton[start:start + num_seq])\n",
        "                    Y.append(labels_pertime[start + num_seq])\n",
        "                    vid_list.append(item[0])\n",
        "                    start_list.append(start)\n",
        "                    start = start + ovr_num\n",
        "                X.append(skeleton[-num_seq:])\n",
        "                Y.append(labels_pertime[-1])\n",
        "                vid_list.append(item[0])\n",
        "                start_list.append(skeleton.shape[0] - num_seq)\n",
        "            else:\n",
        "                skeleton = np.concatenate((np.zeros((num_seq - skeleton.shape[0], skeleton.shape[1], skeleton.shape[2])), skeleton), axis=0)\n",
        "                labels_pertime = np.concatenate((np.zeros((num_seq - labels_pertime.shape[0], labels_pertime.shape[1])), labels_pertime), axis=0)\n",
        "                X.append(skeleton)\n",
        "                Y.append(labels_pertime[-1])\n",
        "                vid_list.append(item[0])\n",
        "                start_list.append(0)\n",
        "\n",
        "    X = np.asarray(X).astype(np.float32)\n",
        "    Y = np.asarray(Y)\n",
        "    print(X.shape, Y.shape)\n",
        "    return X, Y, vid_list, start_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5yk4n6Z519l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsOqIhgIk1RF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param = {'max_iter': 500, 'step_inter': 80, 'base_learn_rate': 0.01, 'lr_gamma': 0.5, 'weight_regular': 0, 'num_seq': 200, 'batchsize': 1024, 'write_file': True,\n",
        "         'num_joints': 25, 'num_class': 51 + 1, 'dim_point': 3 * 2, 'key_seq': 30, 'sub_mean': True}\n",
        "param['trn_file'] = F\"/content/drive/My Drive/crs_view_trn_skt\"\n",
        "param['val_file'] = F\"/content/drive/My Drive/crs_view_val_skt\"\n",
        "param['save_path'] = F\"/content/drive/My Drive/gcn/gcn/weights.hdf5\"\n",
        "param['write_file_name'] = F\"/content/drive/My Drive/gcn/gcn.txt\"\n",
        "# no batch size, as one batch only\n",
        "\n",
        "trainX, trainY, train_vid_list, train_start_list = load_seq_lst(param['trn_file'], param['num_seq'])\n",
        "valX, valY, val_vid_list, val_start_list = load_seq_lst(param['val_file'], param['num_seq'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k1Evqx0S22r_"
      },
      "source": [
        "Use `tf.data` to batch and shuffle the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8Iu_quO024c2",
        "colab": {}
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((trainX, trainY)).shuffle(10000).batch(32)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((valX, valY)).batch(32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BPZ68wASog_I"
      },
      "source": [
        "Build the `tf.keras` model using the Keras [model subclassing API](https://www.tensorflow.org/guide/keras#model_subclassing):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h3IKyzTCDNGo",
        "colab": {}
      },
      "source": [
        "class DRLModel(Model):    \n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        skt_input = Input(shape=(param['num_seq'], param['num_joints'], param['dim_point']))\n",
        "        data = skt_input\n",
        "\n",
        "        if param['sub_mean']:\n",
        "            data = Permute((1, 3, 2))(data)\n",
        "            data2 = TimeDistributed(TimeDistributed(Dense(1, trainable=False)))(data)\n",
        "            data2 = Lambda(lambda x: tf.keras.backend.repeat_elements(x, param['num_joints'], axis=-1), output_shape=lambda s: (s[0], s[1], s[2], s[3] * self.param['num_joints']))(data2)\n",
        "            data = Add()([data, data2])\n",
        "\n",
        "        data = Reshape((param['num_seq'], param['num_joints'] * param['dim_point']))(data)\n",
        "\n",
        "        hid_size = 256\n",
        "        out = Bidirectional(LSTM(hid_size, return_sequences=True))(data)\n",
        "        # out = SpatialDropout1D(0.05)(out)\n",
        "        out = Bidirectional(LSTM(hid_size, return_sequences=False))(out)\n",
        "        out = BatchNormalization()(out)\n",
        "        out = Activation('relu')(Dropout(0.5)(out))\n",
        "        # out = Add()([out, mask])\n",
        "        return Dense(3, activation='softmax')(out)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = DRLModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uGih-c2LgbJu"
      },
      "source": [
        "Choose an optimizer and loss function for training: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u48C9WQ774n4",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JB6A1vcigsIe"
      },
      "source": [
        "Select metrics to measure the loss and the accuracy of the model. These metrics accumulate the values over epochs and then print the overall result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N0MqHFb4F_qn",
        "colab": {}
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.Mean(name='test_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGzo0NORyeTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_select_frame():\n",
        "    selected_frames = np.full((param['num_seq']), 0.0)\n",
        "    selected = random.sample(range(0, param['num_seq']), param['key_seq'])\n",
        "    for s in selected:\n",
        "        selected_frames[s] = 1\n",
        "    return selected, selected_frames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khYyX9XVQ96r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def choose_action(actions, selected):\n",
        "  selected = np.array(selected)\n",
        "  print(\"choose action\")\n",
        "  print(selected.shape)\n",
        "  print(selected)\n",
        "  print(actions.shape)\n",
        "  print(actions.numpy())\n",
        "  for x in range(actions.shape[0] -1):\n",
        "    print(x)\n",
        "    print(actions[x])\n",
        "    if actions[x] == 1:\n",
        "      if selected[x] != param['key_seq']:\n",
        "          selected[x] = selected[x] + 1\n",
        "    elif actions[x] == 2:\n",
        "      if selected[x] != 0:\n",
        "          selected[x] = selected[x] - 1\n",
        "\n",
        "  selected_frames = np.full((param['key_seq']), 0)\n",
        "  for s in selected:\n",
        "      selected_frames[s] = 1\n",
        "  return selected, selected_frames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2eswJ19yaN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(selected_frames, label):\n",
        "    # TODO buralar yapÄ±lacak\n",
        "    return random.randint(50, 90) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANMljxZwbidi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_reward(selected_frames, label, previous_accuracy):\n",
        "    accuracy = evaluate(selected_frames, label)\n",
        "    reward = 0\n",
        "    if previous_accuracy is None:\n",
        "        reward = 0.1\n",
        "    elif previous_accuracy < accuracy:\n",
        "        reward = 1\n",
        "    elif previous_accuracy > accuracy:\n",
        "        reward = -1\n",
        "    return reward, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ix4mEL65on-w"
      },
      "source": [
        "Use `tf.GradientTape` to train the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OZACiVqA8KQV",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(sequence, label):\n",
        "    selected, selected_frames = random_select_frame()\n",
        "    total_reward = 0\n",
        "    for x in range(param['key_seq']):\n",
        "        with tf.GradientTape() as tape:\n",
        "            actions = model(sequence, selected_frames)\n",
        "\n",
        "        selected, selected_frames = choose_action(actions, selected)\n",
        "        reward, previous_accuracy = compute_reward(selected_frames, label, previous_accuracy)\n",
        "        total_reward += reward\n",
        "    gradients = tape.gradient(total_reward * -1, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    train_accuracy(previous_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z8YT7UmFgpjV"
      },
      "source": [
        "Test the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xIKdEzHAJGt7",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def test_step(sequence, label):\n",
        "    selected, selected_frames = random_select_frame()\n",
        "    total_reward = 0\n",
        "    for x in range(param['key_seq']):\n",
        "        with tf.GradientTape() as tape:\n",
        "            actions = model(sequence, selected_frames)\n",
        "\n",
        "        selected, selected_frames = choose_action(actions, selected)\n",
        "        reward, previous_accuracy = compute_reward(selected_frames, label, previous_accuracy)\n",
        "        total_reward += reward\n",
        "    gradients = tape.gradient(total_reward * -1, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    test_accuracy(previous_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i-2pkctU_Ci7",
        "colab": {}
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Reset the metrics at the start of the next epoch\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_accuracy.reset_states()\n",
        "  \n",
        "  for videos, labels in train_ds:\n",
        "    for i in range(videos.shape[0]):\n",
        "      train_step(videos[i], labels[i])\n",
        "\n",
        "  for test_images, test_labels in test_ds:\n",
        "    test_step(test_images, test_labels)\n",
        "\n",
        "  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "  print(template.format(epoch+1,\n",
        "                        train_loss.result(),\n",
        "                        train_accuracy.result()*100,\n",
        "                        test_loss.result(),\n",
        "                        test_accuracy.result()*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T4JfEh7kvx6m"
      },
      "source": [
        "The image classifier is now trained to ~98% accuracy on this dataset. To learn more, read the [TensorFlow tutorials](https://www.tensorflow.org/tutorials)."
      ]
    }
  ]
}